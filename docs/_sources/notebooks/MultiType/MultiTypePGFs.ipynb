{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f19c5eb",
   "metadata": {},
   "source": [
    "# Multivariate Probability Generating Functions\n",
    "\n",
    "We now consider PGFs that depend on multiple variables\n",
    "\n",
    "Let us assume that we have some distribution joint distribution of two non-negative integer random variables $p_{j,k} = P(J=j, K=k)$.  Then we define a two-variable PGF\n",
    "\n",
    "$$\n",
    "\\mu(x,y) = \\sum_{j=0}^\\infty \\sum_{k=0}^\\infty p_{j,k} x^j y^k\n",
    "$$\n",
    "\n",
    "We make a few observations.  First, if we set $x=y=1$, we get\n",
    "\n",
    "$$\n",
    "\\mu(1,1) = \\sum_{j} \\sum_k p_{j,k} = 1\n",
    "$$\n",
    "Next, if we just set $x=1$ or $y=1$ we get the PGFs of the marginal distributions of $k$ and $j$ respectively\n",
    "\n",
    "\\begin{align*}\n",
    "\\mu(1,y) &= \\sum_{k} \\left(\\sum_j p_{j,k}\\right) y^k = \\sum_k P(K=k) y^k\\\\\n",
    "\\mu(x,1) &= \\sum_j P(J=j) x^j \n",
    "\\end{align*}\n",
    "We can find the expected values of $j$ and $k$ through differentiation:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial x} \\mu(1,1) &= \\sum_j \\sum_k j p_{j,k}1^{j-1}1^k = \\mathbb{E}[j]\\\\\n",
    "\\frac{\\partial}{\\partial y} \\mu(1,1) &= \\mathbb{E}[k]\n",
    "\\end{align*}\n",
    "and the expected value of the product is\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2}{\\partial x \\partial y} \\mu(1,1) = \\sum_j \\sum_k jk p_{j,k}1^{j-1}1^{k-1} = \\mathbb{E}[jk]\n",
    "$$\n",
    "\n",
    "These expressions generalize to joint distributions of more than two random variables.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d51e7f",
   "metadata": {},
   "source": [
    "## Sums of random variables\n",
    "\n",
    "We saw earlier that given a probability distribution of non-negative integers $j$ with PGF $\\mu(x) = \\sum_j p_j x^j$, the PGF for the sum of sum exactly $k$ numbers $\\sum_{i=1}^k J_i$ chosen independently from that distribution is $\\mu(x)^k$.  Further, if the number of terms $k$ is itself a random variable, then the PGF for the \"randomly-stopped sum\" $\\sum_{i=1}^k J_i$ is $\\psi(\\mu(x))$ where $\\psi(x)$ is the PGF for $k$.\n",
    "\n",
    "This generalizes to pairs of random non-negative integers.  Let us assume that we have a PGF $\\mu(x,y)$ for the joint distribution of a pair of non-negative integers $(j,k)$.  The PGF of the joint distribution of their sums $\\sum_{i=1}^\\ell (X_i, K_i)$ is $\\mu(x,y)^k$.  If $k$ itself is a random variable with PGF $\\psi(x)$, then the PGF for the joint distribution of the sums is $\\psi(\\mu(x,y))$.\n",
    "\n",
    "```{prf:thm} \n",
    "place theorem here\n",
    "```\n",
    "\n",
    "If we have two different joint distributions $p_{j,k}$ and $q_{j,k}$ with PGFs $\\mu_1(x,y)$, $\\mu_2(x,y)$ and we want to take $\\ell$ pairs $(J_i,K_i)$, $i=1,\\ldots, \\ell$ and another $m$ pairs $(J_{\\ell+i}, K_{\\ell+i})$, $i=1,\\ldots, m$ then the PGF of the sum of all of these pairs is $\\mu_1(x,y)^\\ell \\mu_2(x,y)^m$.  If in turn $\\ell$ and $m$ are random variables whose joint distribution has PGF $\\psi(x,y)$, then the PGF for the sum is $\\psi(\\mu_1(x,y),\\mu_2(x,y))$.\n",
    "\n",
    "```{prf:thm} \n",
    "place theorem here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640590d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
